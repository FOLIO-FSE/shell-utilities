#
#

if [[ -z $1 ]];then
	echo "This tool converts csv data to tsv, performs basic cleaning, and does field frequency counts "
	echo 
	echo "Usage: filefix [filename]"
	echo "You will be prompted for optional functionality"
	echo
	exit
else
	infile=${1}
fi

echo "Detecting and removing trailing carriage returns"
echo
dos2unix ${infile}

# detect file characteristics. First line is assumed to contain either tabs or commas

if awk '{exit !/\t/}' ${infile}; then 
	filetype="tab"
else
	if awk '{exit !/,/}' ${infile}; then filetype="comma"
		echo "Comma delimited file detected. Converting ${infile} to tab delimited."
		echo "Please be patient."
		outfile=$(sed 's/\.....\?$//' <<< ${infile})
		csvtool -t COMMA -u TAB cat ${infile} > "${outfile}.tsv"
		infile="${outfile}.tsv"
		echo "Conversion to tab delimited complete"
		echo
	fi
fi

if [[ ! $filetype ]];then
	echo "${infile} doesn't appear to be comma or tab delimited."
	echo "Please supply a different file or correct the first line."
	echo
	exit
fi

read -r fieldnames < ${infile}

numrecs=$(wc -l ${infile} |cut -d " " -f1)
numfields=$(awk 'BEGIN{FS="\t"}{print NF;exit}' ${infile})

echo
echo "$numfields fields $numrecs lines were detected."
echo "Problematic characters will be removed from fieldnames"
echo

fieldnames=$(tr -dc "[[:alnum:]]_\-#.	" <<< "${fieldnames}")

echo "The following fields were detected in ${infile}"
echo
echo "${fieldnames//	/, }"
echo

echo "Please enter a comma separated list for any fields that you want frequency counts for"
echo

read fieldcounters

echo
echo "Stripping double quotes from the edges of fields and converting smartquotes"
echo

SINGLE=$(echo -ne '\u00B4\u2018\u2019')
DOUBLE=$(echo -ne '\u201C\u201D')
NBSP=$(echo -ne '\uc2a0\u00a0')
#sed -i 's/"*\t"*/\t/g; s/^"//; s/"$// ' ${infile}
sed -i "s/\"*\t\"*/\t/g; s/^\"//; s/\"$//;s/[$SINGLE]/'/g; s/[$DOUBLE]/\"/g; s/[$NBSP]/ /g" "${infile}"


fieldcounters="${fieldcounters// /}"

read -r -d '' awkscript << "ENDOFAWK"
#!/usr/bin/awk -f

BEGIN {
	FS=OFS="\t"
	goodrecs=badrecs=0
	numcounters=split(fieldcounters, fields, ",")
}

{
	# detect counter fields
	if (NR == 1) {
		for(i=1;i<=NF;i++) {
			gsub(/ /, "", $i)
			printf("%s%s",$i,i==NF?RS:OFS) > outfile

			for(j=1;j<=numcounters;j++) {
				if ($i == fields[j]) {
					fieldcounter[j] = i	
				}
			}

		}
	} else {
		if (NF == numfields) {
			goodrecs++
			for(i=1;i<=NF;i++) {
				printf("%s%s",$i,i==NF?RS:OFS) > outfile
				
				# append to file if counter field detected
				for (k=1;k<=numcounters;k++) {
					if (fieldcounter[k] = i) {
						print $i > fields[k]
					}	
				}
			}
	
		} else {
			badrecs++
			print $0 > badfile
		}
	
		if(NR % 10000 == 0 ) {printf ("Processed %d items\r", NR)}
	}
}
END {
	print "Processed " NR - 1 " items."
	print goodrecs " good records were output to " outfile " and" 
	print badrecs " records with the wrong number of fields were output to " badfile
	print ""

	for (k=1;k<=numcounters;k++) {
		print fields[k] > "tmp_counters"
		}
}
ENDOFAWK

echo -e "${awkscript}" > tmp_awk
chmod 700 tmp_awk

outfile="${infile}_fixed"
badfile="${infile}_error"

awk -v numrecs=$numrecs -v numfields=$numfields -v outfile=$outfile -v badfile=$badfile -v fieldcounters=$fieldcounters -f tmp_awk ${infile}
rm tmp_awk

if [[ -f tmp_counters ]];then
	for f in $(cat tmp_counters);do
		echo "Calculating frequency of values for $f"
		sort $f |uniq -c |sort -k1nr > ${f}.counter
		echo "Here are the 10 most common values:"
		head ${f}.counter
		rm ${f}
		echo
		echo "${f}.counter contains the frequency of all values encountered"
		echo
	done
	rm -f tmp_counters
fi

tenant=$(cat tenant)
okapi_url=$(cat okapi.url)
okapi_token=$(cat okapi.token)

marcfile="${1}"
logfile="dataimport_errors.json"

tenant=$(cat tenant)
okapi_url=$(cat okapi.url)
okapi_token=$(cat okapi.token)

errors=0
created=0
updated=0
discarded=0
status=""
SECONDS=0

rm -f ${logfile}


get_summary() {
	apicall=$(curl -s -w '\n' -X GET -H "Accept: application/json" -H "X-Okapi-Tenant: ${tenant}" -H "x-okapi-token: ${okapi_token}" "${okapi_url}/metadata-provider/jobSummary/${jobExecutionId}") 
	batcherrors=$(echo "${apicall}" |jq -r .sourceRecordSummary.totalErrors)
	batchcreated=$(echo "${apicall}" |jq -r .sourceRecordSummary.totalCreatedEntries)
	batchupdated=$(echo "${apicall}" |jq -r .sourceRecordSummary.totalUpdatedEntries)

	created=$(($created + $batchcreated))
	updated=$(($updated + $batchupdated))
	errors=$(($errors + $batcherrors))
	echo
	echo "Created: $created"
	echo "Updated: $updated"
	echo "Errors: $errors"
	echo

	curl -s -w '\n' -X GET -H "Accept: application/json" -H "X-Okapi-Tenant: ${tenant}" -H "x-okapi-token: ${okapi_token}" "${okapi_url}/metadata-provider/jobLogEntries/${jobExecutionId}?entity=SRS_MARC&errorsOnly=true&limit=10000&order=asc" |jq -d '.entries[]' >> ${logfile}

}
check_upload() {
	status=$(curl -s -w '\n' -X GET -H "Accept: application/json" -H "X-Okapi-Tenant: ${tenant}" -H "x-okapi-token: ${okapi_token}" "${okapi_url}/metadata-provider/jobExecutions?statusNot=DISCARDED&uiStatusAny=PREPARING_FOR_PREVIEW&uiStatusAny=READY_FOR_PREVIEW&uiStatusAny=RUNNING" |jq -r ".jobExecutions[] | select(.id = \"${jobExecutionId}\") |select(.status != null) | .status")
	
	TIME=$SECONDS;msg="$SECONDS seconds"

	if [[ $SECONDS -gt 60 ]];then TIME=$(($SECONDS/60));msg="$TIME minutes";fi
	if [[ $SECONDS -gt 3600 ]];then TIME=$(($SECONDS/3600));msg="$TIME hours";fi
	echo  -en "Status: ${status} -- $msg elapsed\r"
}

upload_file() {
	# get job profile 
	jobProfileId=$(curl --http1.1 -s -w '\n' -X GET -H "Accept: application/json" -H "X-Okapi-Tenant: ${tenant}" -H "x-okapi-token: ${okapi_token}" "${okapi_url}/data-import-profiles/jobProfiles?limit=1000" |jq -r '.jobProfiles[] | select(.name=="Default - Create instance and SRS MARC Bib") | .id')
#	jobProfileId=$(curl --http1.1 -s -w '\n' -X GET -H "Accept: application/json" -H "X-Okapi-Tenant: ${tenant}" -H "x-okapi-token: ${okapi_token}" "${okapi_url}/data-import-profiles/jobProfiles?limit=1000" |jq -r '.jobProfiles[] | select(.name=="Backstage Reload--Data Import Test") | .id')
	
	if ! [[ $jobProfileId =~ ^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$ ]]; then
		echo "No valid profile found. Exiting."
		exit
	fi
	
	apicall=$(curl --http1.1 -s -w '\n' -X POST -H "Content-type: application/json" -H "X-Okapi-Tenant: ${tenant}" -H "x-okapi-token: ${okapi_token}" -d "{\"fileDefinitions\":[{ \"name\":\"${marcfile}\"}]}" "${okapi_url}/data-import/uploadDefinitions")
	
	fileId=$(echo ${apicall} | jq -r '.fileDefinitions[0].id')
	jobExecutionId=$(echo ${apicall} | jq -r '.fileDefinitions[0].jobExecutionId')
	uploadDefinitionId=$(echo ${apicall} | jq -r '.fileDefinitions[0].uploadDefinitionId')
	
	echo "${apicall}"
	
	apicall=$(curl --http1.1 -s -w '\n' -X POST -H "Content-type: application/octet-stream" -H "X-Okapi-Tenant: ${tenant}" -H "x-okapi-token: ${okapi_token}" -d "@${marcfile}" "${okapi_url}/data-import/uploadDefinitions/${uploadDefinitionId}/files/${fileId}")
	
	echo "${apicall}"
	
	payload="{\"uploadDefinition\":${apicall},\"jobProfileInfo\": {\"id\": \"${jobProfileId}\", \"dataType\": \"MARC\"}}"
	
	apicall=$(curl --http1.1 -s -w '\n' -X POST -H "Content-type: application/json" -H "X-Okapi-Tenant: ${tenant}" -H "x-okapi-token: ${okapi_token}" -d "${payload}" "${okapi_url}/data-import/uploadDefinitions/${uploadDefinitionId}/processFiles?defaultMapping=true")
	
	echo "${apicall}"
}

upload_file
sleep 10	
check_upload

while [[ ${status} != "" ]];do
	check_upload
	sleep 5
done

get_summary
echo "Errors have been output to ${logfile}"
